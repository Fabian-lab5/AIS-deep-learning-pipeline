{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (papermill will inject these)\n",
    "augmentation_type = \"default\"  # Default value, overridden by papermill\n",
    "seed = -1      # Default value, overridden by papermill\n",
    "num_aug = -1  # Default value, overridden by papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_seed = 3141\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "random.seed(comparison_seed)\n",
    "np.random.seed(comparison_seed)\n",
    "tf.random.set_seed(comparison_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataframe(df):\n",
    "    display(df)\n",
    "    \n",
    "    unique_vessel_groups = df['VesselGroup'].unique()\n",
    "    num_vessel_groups = df['VesselGroup'].nunique()\n",
    "    \n",
    "    num_rows = f\"{len(df):,}\"\n",
    "    \n",
    "    print(f\"The dataframe contains {num_rows} rows.\")\n",
    "    print()\n",
    "    print(f\"There are {num_vessel_groups} unique vessel groups.\")\n",
    "    print(f\"The unique vessel groups are: {unique_vessel_groups}\")\n",
    "    \n",
    "    print(\"\\nRow counts for each vessel group:\")\n",
    "    for group in unique_vessel_groups:\n",
    "        group_count = len(df[df['VesselGroup'] == group])\n",
    "        print(f\"Group {group}: {group_count:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Variables after GridSearch\n",
    "window_size = 50 \n",
    "step_size = 1 \n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "lstm_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if augmentation_type == \"baseline\":\n",
    "    run_name = f\"baseline_{seed}\"\n",
    "else:\n",
    "    run_name = f\"{augmentation_type}_aug{num_aug}_{seed}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if augmentation_type == \"baseline\" and num_aug == 0:\n",
    "    # Path for no augmentation (baseline data without aug)\n",
    "    file_path = f\"/Users/fabian/Downloads/MasterDegree/df_train_{seed}.csv\"\n",
    "    print(file_path)\n",
    "else:\n",
    "    # Path for augmented data\n",
    "    folder_name = augmentation_type.replace(\" \", \"_\")\n",
    "    \n",
    "    if augmentation_type == \"GNI\":\n",
    "        file_prefix = \"GNI\"\n",
    "    elif augmentation_type == \"vae\":\n",
    "        file_prefix = \"vae\"\n",
    "    elif augmentation_type == \"kmeans\":\n",
    "        file_prefix = \"kmeans\"\n",
    "\n",
    "    file_path = f\"/Users/fabian/Downloads/MasterDegree/{file_prefix}/{file_prefix}{seed}/df_{file_prefix}_{num_aug}.csv\"\n",
    "    print(file_path)\n",
    "\n",
    "df_train = pd.read_csv(file_path)\n",
    "df_test = pd.read_csv(f\"/Users/fabian/Downloads/MasterDegree/df_test_{seed}.csv\")\n",
    "df_val = pd.read_csv(f\"/Users/fabian/Downloads/MasterDegree/df_val_{seed}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n===== Train Data =====\")\n",
    "summarize_dataframe(df_train)\n",
    "\n",
    "print(f\"\\n===== Test Data =====\")\n",
    "summarize_dataframe(df_test)\n",
    "\n",
    "print(f\"\\n===== Validation Data =====\")\n",
    "summarize_dataframe(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(df_train)\n",
    "test_size = len(df_test)\n",
    "val_size = len(df_val)\n",
    "\n",
    "rows_sum = train_size + test_size + val_size\n",
    "\n",
    "print(f\"The DataFrame (without augmentation) contains {rows_sum} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_vessel_groups = df_train['VesselGroup'].unique()\n",
    "print(unique_vessel_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Dataset'] = 'train'\n",
    "df_val['Dataset'] = 'val'\n",
    "df_test['Dataset'] = 'test'\n",
    "\n",
    "combined_data = pd.concat([df_train, df_val, df_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nCombined dataset preview:\")\n",
    "print(combined_data[['LAT', 'LON', 'SOG', 'COG', 'Dataset']].head())\n",
    "\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_targets = MinMaxScaler()\n",
    "\n",
    "scaler_features.fit(combined_data[['LAT', 'LON', 'SOG', 'COG']])\n",
    "scaler_targets.fit(combined_data[['LAT', 'LON']])\n",
    "\n",
    "print(\"\\nScaler Features Min/Max:\")\n",
    "print(\"Min:\", scaler_features.data_min_)\n",
    "print(\"Max:\", scaler_features.data_max_)\n",
    "\n",
    "print(\"\\nScaler Targets Min/Max:\")\n",
    "print(\"Min:\", scaler_targets.data_min_)\n",
    "print(\"Max:\", scaler_targets.data_max_)\n",
    "\n",
    "combined_data[['LAT', 'LON', 'SOG', 'COG']] = scaler_features.transform(combined_data[['LAT', 'LON', 'SOG', 'COG']])\n",
    "\n",
    "scaled_train = combined_data[combined_data['Dataset'] == 'train'].drop(columns=['Dataset']).reset_index(drop=True)\n",
    "scaled_val = combined_data[combined_data['Dataset'] == 'val'].drop(columns=['Dataset']).reset_index(drop=True)\n",
    "scaled_test = combined_data[combined_data['Dataset'] == 'test'].drop(columns=['Dataset']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDEBUG: Row Counts - Train: {len(scaled_train)}, Val: {len(scaled_val)}, Test: {len(scaled_test)}\")\n",
    "print(\"\\nScaled Train Data Preview:\")\n",
    "print(scaled_train[['LAT', 'LON', 'SOG', 'COG']].head())\n",
    "print(\"\\nScaled Validation Data Preview:\")\n",
    "print(scaled_val[['LAT', 'LON', 'SOG', 'COG']].head())\n",
    "print(\"\\nScaled Test Data Preview:\")\n",
    "print(scaled_test[['LAT', 'LON', 'SOG', 'COG']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combined_data(df, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Preprocess data for the combined dataset while maintaining MMSI-based sequences.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The scaled DataFrame containing the data.\n",
    "        window_size (int): The size of the sliding window.\n",
    "        step_size (int): The step size for the sliding window.\n",
    "\n",
    "    Returns:\n",
    "        X (np.ndarray): Feature sequences of shape (num_samples, window_size, num_features).\n",
    "        y (np.ndarray): Target values of shape (num_samples, num_targets).\n",
    "    \"\"\"\n",
    "    # Ensure the dataset is sorted by MMSI and time to maintain sequences\n",
    "    df = df.sort_values(['MMSI', 'BaseDateTime']).reset_index(drop=True)\n",
    "\n",
    "    features = df[['LAT', 'LON', 'SOG', 'COG']].values\n",
    "    targets = df[['LAT', 'LON']].values\n",
    "\n",
    "    X, y = [], []\n",
    "    for mmsi, group in df.groupby('MMSI'):\n",
    "        data = features[group.index]\n",
    "        target = targets[group.index]\n",
    "\n",
    "        for i in range(0, len(data) - window_size, step_size):\n",
    "            X.append(data[i:i + window_size])\n",
    "            y.append(target[i + window_size])\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_predictions(y_test, y_pred, scaler_targets):\n",
    "    \"\"\"\n",
    "    Rescale predictions and actual values back to their original range.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (np.ndarray): Actual scaled test target values (LAT, LON).\n",
    "        y_pred (np.ndarray): Predicted scaled test target values (LAT, LON).\n",
    "        scaler_targets (MinMaxScaler): Scaler used for inverse transformation.\n",
    "\n",
    "    Returns:\n",
    "        original_actuals, original_predictions (np.ndarray, np.ndarray): Rescaled actuals and predictions.\n",
    "    \"\"\"\n",
    "    y_test = y_test.reshape(-1, 2)\n",
    "    y_pred = y_pred.reshape(-1, 2)\n",
    "\n",
    "    original_actuals = scaler_targets.inverse_transform(y_test)\n",
    "    original_predictions = scaler_targets.inverse_transform(y_pred)\n",
    "\n",
    "    print(\"\\nDEBUG: Rescaled Values Validation\")\n",
    "    for i in range(min(5, len(original_actuals))):\n",
    "        print(f\"Row {i}:\")\n",
    "        print(f\"  Scaled Actual: {y_test[i]}\")\n",
    "        print(f\"  Rescaled Actual: {original_actuals[i]}\")\n",
    "        print(f\"  Scaled Predicted: {y_pred[i]}\")\n",
    "        print(f\"  Rescaled Predicted: {original_predictions[i]}\")\n",
    "\n",
    "    return original_actuals, original_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparison_df(y_test, y_pred, test_data, scaler_targets):\n",
    "    \"\"\"\n",
    "    Generates a detailed comparison DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        y_test (np.ndarray): Actual scaled test target values (LAT, LON).\n",
    "        y_pred (np.ndarray): Predicted scaled test target values (LAT, LON).\n",
    "        test_data (DataFrame): Original test data containing metadata (LAT, LON, etc.).\n",
    "        scaler_targets (MinMaxScaler): Pre-fitted scaler used for inverse transformation.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A detailed comparison DataFrame with Haversine distances.\n",
    "    \"\"\"\n",
    "    y_test_flattened = y_test.reshape(-1, 2)\n",
    "    y_pred_flattened = y_pred.reshape(-1, 2)\n",
    "\n",
    "    original_actuals = scaler_targets.inverse_transform(y_test_flattened)\n",
    "    original_predictions = scaler_targets.inverse_transform(y_pred_flattened)\n",
    "\n",
    "    print(\"\\nDEBUG: Rescaled Values Comparison\")\n",
    "    print(\"Original LAT/LON from test_data:\")\n",
    "    print(test_data[['LAT', 'LON']].iloc[:5].values) \n",
    "    print(\"Rescaled Actuals (Original Range):\")\n",
    "    print(original_actuals[:5]) \n",
    "    print(\"Rescaled Predictions (Original Range):\")\n",
    "    print(original_predictions[:5])\n",
    "\n",
    "    metadata = test_data.iloc[:len(y_pred_flattened)].reset_index(drop=True)\n",
    "\n",
    "    if len(metadata) != len(original_predictions):\n",
    "        print(\n",
    "            f\"\\nWARNING: Metadata length ({len(metadata)}) does not match predictions ({len(original_predictions)})\"\n",
    "        )\n",
    "\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'BaseDateTime': metadata['BaseDateTime'],\n",
    "        'MMSI': metadata['MMSI'],\n",
    "        'VesselGroup': metadata['VesselGroup'],\n",
    "        'Actual LAT': original_actuals[:, 0],\n",
    "        'Actual LON': original_actuals[:, 1],\n",
    "        'Predicted LAT': original_predictions[:, 0],\n",
    "        'Predicted LON': original_predictions[:, 1],\n",
    "    })\n",
    "\n",
    "    comparison_df['Haversine Distance (km)'] = haversine(\n",
    "        comparison_df['Actual LAT'], comparison_df['Actual LON'],\n",
    "        comparison_df['Predicted LAT'], comparison_df['Predicted LON']\n",
    "    )\n",
    "\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_scaling_and_rescaling(group_test, scaler_features, scaler_targets):\n",
    "    \"\"\"\n",
    "    Verifies if the scaling and rescaling for features and targets are consistent.\n",
    "\n",
    "    Parameters:\n",
    "        group_test (DataFrame): The test data containing LAT, LON, SOG, and COG.\n",
    "        scaler_features (MinMaxScaler): Pre-fitted scaler used for features (LAT, LON, SOG, COG).\n",
    "        scaler_targets (MinMaxScaler): Pre-fitted scaler used for target values (LAT, LON).\n",
    "    \"\"\"\n",
    "    feature_columns = ['LAT', 'LON', 'SOG', 'COG']\n",
    "    target_columns = ['LAT', 'LON']\n",
    "\n",
    "    scaled_features = scaler_features.transform(group_test[feature_columns])\n",
    "    rescaled_features = scaler_features.inverse_transform(scaled_features)\n",
    "\n",
    "    scaled_targets = scaler_targets.transform(group_test[target_columns])\n",
    "    rescaled_targets = scaler_targets.inverse_transform(scaled_targets)\n",
    "\n",
    "    feature_comparison = pd.DataFrame(rescaled_features, columns=feature_columns)\n",
    "    feature_comparison['Original LAT'] = group_test['LAT'].values\n",
    "    feature_comparison['Original LON'] = group_test['LON'].values\n",
    "    feature_comparison['LAT Difference'] = feature_comparison['Original LAT'] - feature_comparison['LAT']\n",
    "    feature_comparison['LON Difference'] = feature_comparison['Original LON'] - feature_comparison['LON']\n",
    "\n",
    "    inconsistent_features = feature_comparison[\n",
    "        (feature_comparison['LAT Difference'].abs() > 1e-6) |\n",
    "        (feature_comparison['LON Difference'].abs() > 1e-6)\n",
    "    ]\n",
    "\n",
    "    print(\"\\nChecking Scaling and Rescaling Consistency for Features:\")\n",
    "    print(f\"Number of inconsistent rows in features: {len(inconsistent_features)}\")\n",
    "\n",
    "    if not inconsistent_features.empty:\n",
    "        print(\"Sample inconsistencies for features:\")\n",
    "        print(inconsistent_features.head())\n",
    "\n",
    "    target_comparison = pd.DataFrame(rescaled_targets, columns=target_columns)\n",
    "    target_comparison['Original LAT'] = group_test['LAT'].values\n",
    "    target_comparison['Original LON'] = group_test['LON'].values\n",
    "    target_comparison['LAT Difference'] = target_comparison['Original LAT'] - target_comparison['LAT']\n",
    "    target_comparison['LON Difference'] = target_comparison['Original LON'] - target_comparison['LON']\n",
    "\n",
    "    inconsistent_targets = target_comparison[\n",
    "        (target_comparison['LAT Difference'].abs() > 1e-6) |\n",
    "        (target_comparison['LON Difference'].abs() > 1e-6)\n",
    "    ]\n",
    "\n",
    "    print(\"\\nChecking Scaling and Rescaling Consistency for Targets:\")\n",
    "    print(f\"Number of inconsistent rows in targets: {len(inconsistent_targets)}\")\n",
    "\n",
    "    if not inconsistent_targets.empty:\n",
    "        print(\"Sample inconsistencies for targets:\")\n",
    "        print(inconsistent_targets.head())\n",
    "\n",
    "    return {\n",
    "        \"feature_comparison\": feature_comparison,\n",
    "        \"inconsistent_features\": inconsistent_features,\n",
    "        \"target_comparison\": target_comparison,\n",
    "        \"inconsistent_targets\": inconsistent_targets\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri='http://127.0.0.1:5000')\n",
    "mlflow.set_experiment(\"Final LAT_LON Pred Baseline\")\n",
    "\n",
    "group_count = df_train['VesselGroup'].nunique()\n",
    "\n",
    "avg_haversine_sum = 0\n",
    "\n",
    "avg_haversine_tanker = 0\n",
    "avg_haversine_fishing = 0\n",
    "avg_haversine_cargo = 0\n",
    "\n",
    "average_haversine_distances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_groups = df_train['VesselGroup'].unique()\n",
    "num_classes = df_train['VesselGroup'].nunique()\n",
    "print(num_classes)\n",
    "print(\"Vessel groups found:\", vessel_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape, lstm_units):\n",
    "    \"\"\"\n",
    "    Creates an LSTM model for predicting LAT and LON.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): The shape of the input data (window_size, num_features).\n",
    "        lstm_units (int): Number of LSTM units.\n",
    "\n",
    "    Returns:\n",
    "        model (keras.Model): Compiled LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, activation='relu', input_shape=input_shape, return_sequences=True))\n",
    "    model.add(LSTM(lstm_units, activation='relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    print(\"\\n===== Processing All Vessel Groups Together =====\")\n",
    "\n",
    "    train_data = scaled_train\n",
    "    test_data = scaled_test\n",
    "    val_data = scaled_val\n",
    "\n",
    "    X_train, y_train = preprocess_combined_data(train_data, window_size, step_size)\n",
    "    X_test, y_test = preprocess_combined_data(test_data, window_size, step_size)\n",
    "    X_val, y_val = preprocess_combined_data(val_data, window_size, step_size)\n",
    "\n",
    "    print(\"\\nDEBUG: Dataset shapes after preprocessing:\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"y_val shape: {y_val.shape}\")\n",
    "\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = create_lstm_model(input_shape, lstm_units)\n",
    "    model.summary()\n",
    "\n",
    "    model_architecture = model.to_json()\n",
    "    file_path = \"model_architecture_reg.json\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(model_architecture)\n",
    "\n",
    "    train_data.to_csv(\"df_train_reg.csv\", index=False)\n",
    "\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"window_size\", window_size)\n",
    "    mlflow.log_param(\"step size\", step_size)\n",
    "    mlflow.log_param(\"lstm_units\", lstm_units)\n",
    "    mlflow.log_param(\"num_classes\", num_classes)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"train_size\", train_size)\n",
    "    mlflow.log_param(\"test_size\", test_size)\n",
    "    mlflow.log_param(\"val_size\", val_size)\n",
    "    mlflow.log_param(\"rows_sum\", rows_sum)\n",
    "    mlflow.log_param(\"num_aug\", num_aug)\n",
    "    mlflow.log_param(\"aug_type\", augmentation_type)\n",
    "    mlflow.log_param(\"seed\", seed)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"all_vessel_groups_model\")\n",
    "    mlflow.log_artifact(\"df_train_reg.csv\")\n",
    "    mlflow.log_artifact(file_path)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "        )\n",
    "\n",
    "    for epoch, loss in enumerate(history.history['loss']):\n",
    "        mlflow.log_metric(\"Training Loss\", loss, step=epoch)\n",
    "    for epoch, val_loss in enumerate(history.history['val_loss']):\n",
    "        mlflow.log_metric(\"Validation Loss\", val_loss, step=epoch)\n",
    "\n",
    "    print(\"\\nPredicting for All Vessel Groups:\")\n",
    "    y_pred = model.predict(X_test, batch_size=32)\n",
    "    print(f\"Number of samples in X_test: {len(X_test)}\")\n",
    "    print(f\"Number of predictions: {len(y_pred)}\")\n",
    "\n",
    "    comparison_df = generate_comparison_df(y_test, y_pred, test_data, scaler_targets)\n",
    "    assert len(comparison_df) == len(y_pred), \"Mismatch between comparison_df and predictions\"\n",
    "\n",
    "    display(comparison_df)\n",
    "\n",
    "    avg_haversine = comparison_df['Haversine Distance (km)'].mean()\n",
    "    mlflow.log_metric(\"Average Haversine Distance\", avg_haversine)\n",
    "    print(f\"Average Haversine Distance: {avg_haversine:.4f} km\")\n",
    "\n",
    "    large_haversine = 50\n",
    "    large_distances = comparison_df[comparison_df['Haversine Distance (km)'] > large_haversine]\n",
    "    print()\n",
    "    print(f\"Rows with extreme large haversine distances greater than {large_haversine}:\")\n",
    "    display(large_distances)\n",
    "\n",
    "    os.remove(\"df_train_reg.csv\")\n",
    "    os.remove(\"model_architecture_reg.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
